# Core dependencies
gradio>=4.0.0
transformers>=4.40.0
torch>=2.0.0
pillow>=10.0.0
huggingface-hub>=0.20.0
pyyaml>=6.0
accelerate>=0.25.0

# Qwen2-VL specific
qwen-vl-utils
torchvision>=0.15.0

# 量子化モデル用（オプション）
auto-gptq
optimum

# GGUF モデル用（llama.cpp backend with vision support）
# llama-cpp-python>=0.2.0  # オプショナル: GGUF形式を使う場合のみインストール

# Optional dependencies
# Additional utilities if needed
